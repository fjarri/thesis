% =============================================================================
\section{Mean-field approximation}
% =============================================================================

We will start from the classical model of a trapped \abbrev{bec} --- the mean-field approximation.
While it cannot predict quantum effects, it provides the basis for comparison with the truncated Wigner method, and can be also applied to calculate the ground state of a trapped \abbrev{bec} numerically.
For definiteness we will consider a two-component \abbrev{bec}, although the equations in this section can be easily generalised to describe an arbitrary number of components.


% =============================================================================
\subsection{Two-component condensate}
% =============================================================================

The classical \abbrev{bec} is described by the wavefunctions $\Psi_j$, which are normalized such that $\int |\Psi_j|^2 \upd\xvec \equiv N_j$, where $N_j$ is the total population of the component $j$ (consequently, $|\Psi_j|^2 \equiv n_j$ is the component density).
The evolution of the condensate is described by the system of coupled Gross-Pitaevskii equations
\begin{eqn}
\label{eqn:bec-noise:mean-field:cgpes}
	i \hbar \frac{\upd \Psi_1}{\upd t} ={} & \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_1 + \hbar \omega_1
		+ g_{11} \lvert \Psi_1 \rvert^2
		+ g_{12} \lvert \Psi_2 \rvert^2
		- i \hbar \Gamma_1
	\right) \Psi_1 \\
	& + \frac{\hbar \Omega}{2} \left(
		e^{i (\omega t + \alpha)} + e^{-i (\omega t + \alpha)}
	\right) \Psi_2, \\
	i \hbar \frac{\upd \Psi_2}{\upd t} ={} & \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_2 + \hbar \omega_2
		+ g_{22} \lvert \Psi_2 \rvert^2
		+ g_{12} \lvert \Psi_1 \rvert^2
		- i \hbar \Gamma_2
	\right) \Psi_2 \\
	& + \frac{\hbar \Omega}{2} \left(
		e^{i (\omega t + \alpha)} + e^{-i (\omega t + \alpha)}
	\right) \Psi_1.
\end{eqn}
Here $V_j(\xvec)$ are external potentials, $\omega_j$ is the internal energy of the component $j$, $g_{jk} = 4 \pi \hbar^2 a_{jk} / m$ are nonlinear interaction coefficients (where $a_{jk}$ are the scattering lengths), $\Gamma_j$ represent nonlinear losses for the component $j$, and $\Omega$ is the electromagnetic coupling strength (with $\omega$ being the frequency, and $\alpha$ the phase of the coupling).
The \abbrev{cgpe}s without loss or coupling terms were introduced in~\cite{Zeng1995,Ho1996}.
The coupling terms were first included in~\cite{Ballagh1997}, and the loss terms in~\cite{Yurovsky1999}.
A detailed description of the mean-field approximation can be found in~\cite{Pitaevskii2003}.

The exact expression of the loss parameters $\Gamma_j$ depends on the loss processes in the particular experiment.
For example, the dominant three-body and two-body losses in the two-component \Rb \abbrev{bec} with the components ${\ket{F=1,\, m_F=-1}}$ and ${\ket{F=2,\, m_F=+1}}$ result in
\begin{eqn}
	\Gamma_1 &= \left( \gamma_{111} n_1^2 + \gamma_{12} n_2 \right) / 2, \\
	\Gamma_2 &= \left( \gamma_{12} n_1 + \gamma_{22} n_2 \right) / 2.
\end{eqn}
We have already seen in \secref{wigner-bec:examples}, and will see later in this chapter, how the same (in the first-order term) expressions appear as a result of the application of the truncated Wigner method to the exact operator equation.

The difference between the internal energies of spins $1$ and $2$ is the hyperfine frequency $\omega_{hf} = \omega_1 - \omega_2$.
The coupling frequency $\omega$ is usually slightly detuned from the hyperfine frequency in the experiment: $\omega = \omega_{hf} + \delta$, where $\delta \ll \omega_{hf}$.

The fact that $\hbar \omega_j \gg V_j$ can cause problems when performing calculations with low precision.
Therefore it is convenient to use equations~\eqnref{bec-noise:mean-field:cgpes} in a rotating frame:
\begin{eqn}
	\Psi_1 & \rightarrow \Psi_1 e^{i \omega_1 t}, \\
	\Psi_2 & \rightarrow \Psi_2 e^{i \omega_2 t}.
\end{eqn}
This transformation eliminates $\omega_1$ and $\omega_2$ from the equations and does not change single-time observable values.
The transformed equations look like:
\begin{eqn}
	i \hbar \frac{\upd \Psi_1}{\upd t} ={} & \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_1
		+ g_{11} \lvert \Psi_1 \rvert^2
		+ g_{12} \lvert \Psi_2 \rvert^2
		- i \hbar \Gamma_1
	\right) \Psi_1 \\
	& + \frac{\hbar \Omega}{2} \left(
		e^{i ((\omega + \omega_{hf}) t + \alpha)} + e^{-i (\delta t + \alpha)}
	\right) \Psi_2, \\
	i \hbar \frac{\upd \Psi_2}{\upd t} ={} & \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_2
		+ g_{22} \lvert \Psi_2 \rvert^2
		+ g_{12} \lvert \Psi_1 \rvert^2
		- i \hbar \Gamma_2
	\right) \Psi_2 \\
	& + \frac{\hbar \Omega}{2} \left(
		e^{i (\delta t + \alpha)} + e^{-i ((\omega + \omega_{hf}) t + \alpha)}
	\right) \Psi_1.
\end{eqn}

Furthermore, in the experiment the coupling field is applied for short periods of time $t_{\mathrm{pulse}}$, where $1 / \omega \ll t_{\mathrm{pulse}} \ll 1 / \delta$.
This allows us to neglect the quickly oscillating terms:
\begin{eqn}
\label{eqn:bec-noise:mean-field:cgpes-simplified}
	i \hbar \frac{\upd \Psi_1}{\upd t} & = \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_1
		+ g_{11} \lvert \Psi_1 \rvert^2
		+ g_{12} \lvert \Psi_2 \rvert^2
		- i \hbar \Gamma_1
	\right) \Psi_1
	+ \frac{\hbar \Omega}{2} e^{-i (\delta t + \alpha)} \Psi_2, \\
	i \hbar \frac{\upd \Psi_2}{\upd t} & = \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_2
		+ g_{22} \lvert \Psi_2 \rvert^2
		+ g_{12} \lvert \Psi_1 \rvert^2
		- i \hbar \Gamma_2
	\right) \Psi_2 +
	\frac{\hbar \Omega}{2} e^{i (\delta t + \alpha)} \Psi_1.
\end{eqn}
When the pulse is applied twice using the same coupling field (which is the case for the Ramsey interferometry), it is the same as just setting $\Omega$ to zero after the first pulse and then restoring its value for the time of the second pulse; therefore $\alpha$ stays the same too.
If one wants to apply pulse with the different detuning, the phase information is lost, and the value of $\alpha$ has to become random before this pulse.

The application of the coupling field can be simplified, if certain additional conditions are valid, namely:
\begin{enumerate}
	\item $\mu / \hbar \ll \Omega$, where $\mu$ is the chemical potential of the first component;
	\item $\delta \ll \Omega$;
	\item the characteristic time of the other terms in~\eqnref{bec-noise:mean-field:cgpes} is much greater than $t_{\mathrm{pulse}}$.
\end{enumerate}
This allows us to use the ``instantaneous'' pulse, multiplying the state vector by a rotation matrix:
\begin{eqn}
\label{eqn:bec-noise:mean-field:rotation-matrix}
	\begin{pmatrix}
		\Psi^\prime_1 \\ \Psi^\prime_2
	\end{pmatrix} =
	\begin{pmatrix}
		\cos \frac{\theta}{2} & -i e^{-i \phi} \sin \frac{\theta}{2} \\
		-i e^{i \phi} \sin \frac{\theta}{2} & \cos \frac{\theta}{2}
	\end{pmatrix}
	\begin{pmatrix}
		\Psi_1 \\ \Psi_2
	\end{pmatrix},
\end{eqn}
where $\theta = \Omega t_{\mathrm{pulse}}$, and $\phi$ is the phase of the coupling field at the beginning of the pulse.
In particular, for the two-pulse Ramsey scheme with the time $t_R$ between pulses, $\phi_2 = \phi_1 + \delta t_R$.


% =============================================================================
\subsection{Ground state calculation}
% =============================================================================

At the beginning of the simulation the \abbrev{bec} is assumed to be in the ground state which has the lowest possible energy.
The ground state is a solution of the stationary \abbrev{cgpe}s
\begin{eqn}
\label{eqn:bec-noise:mean-field:cgpes-stationary}
	\mu_1 \Psi_1 & = \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_1
		+ g_{11} \lvert \Psi_1 \rvert^2
		+ g_{12} \lvert \Psi_2 \rvert^2
	\right) \Psi_1, \\
	\mu_2 \Psi_2 & = \left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_2
		+ g_{22} \lvert \Psi_2 \rvert^2
		+ g_{12} \lvert \Psi_1 \rvert^2
	\right) \Psi_2,
\end{eqn}
where $\mu_1$ and $\mu_2$ are chemical potentials of the components.

The most common method to find the ground state is the imaginary time propagation~\cite{Chiofalo2000,Bao2004}.
The essense of the method is that propagating an arbitrary wavefunction using the time-dependent \abbrev{cgpe}s, but with the substitution $t \rightarrow \tau = it$, lowers its energy; therefore after the sufficient amount of time this propagation will lead us arbitrarily close to the ground state.
The actual equations to be propagated are~\eqnref{bec-noise:mean-field:cgpes-simplified} without the loss or coupling terms:
\begin{eqn}
\label{eqn:bec-noise:mean-field:imaginary-time}
	\hbar \frac{\upd \Psi_1}{\upd \tau} & = -\left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_1
		+ g_{11} \lvert \Psi_1 \rvert^2
		+ g_{12} \lvert \Psi_2 \rvert^2
	\right) \Psi_1, \\
	\hbar \frac{\upd \Psi_2}{\upd \tau} & = -\left(
		-\frac{\hbar^2 \nabla^2}{2 m} + V_2
		+ g_{22} \lvert \Psi_2 \rvert^2
		+ g_{12} \lvert \Psi_1 \rvert^2
	\right) \Psi_2.
\end{eqn}

The rigorous proof of this method can be found in~\cite{Bao2004}.
The idea can be roughly illustrated by considering a one-component system with the linear Hamiltonian $\hat{H}$, whose eigenvalues are $\mu_1 < \mu_2 < ...$, where the lowest eigenvalue corresponds to ground state we want to find.
The steady solution of the time-dependent \abbrev{gpe}
\begin{eqn}
	i \hbar \frac{\upd \Psi}{\upd t} = \hat{H} \Psi
\end{eqn}
then looks like
\begin{eqn}
	\Psi(\xvec, t) = \sum_k e^{-\frac{i}{\hbar}\mu_k t} f_k(\xvec),
\end{eqn}
where $f_k$ are eigenfunctions of $\hat{H}$ corresponding to the eigenvalues $\mu_k$.
After the substitution $t \rightarrow \tau = it$ the solution will become fading, with higher-energy components fading faster:
\begin{eqn}
	\Psi(\xvec, \tau) = \sum_k e^{-\frac{1}{\hbar}\mu_k \tau} f_k(\xvec).
\end{eqn}

Therefore, if we take some random initial solution and propagate it long enough in imaginary time using~\eqnref{bec-noise:mean-field:imaginary-time}, the higher-energy components will eventually die out (in comparison with the lowest-energy state) and leave us with the desired ground state.
The state obtained from the Thomas-Fermi approximated \abbrev{gpe} can be taken as the initial one, since it is rather close to the desired one (and, therefore, higher-energy components are already quite small).

Since the population will decrease exponentially after each step, and the precision of numerical calculations is limited, renormalisation after each step will be required.
Known total number of atoms in ground state serves best in this case (because we will have to renormalise the final ground state anyway):
\begin{eqn}
	\int\limits_V \lvert \Psi(\tau, \xvec) \rvert^2 \upd V = N.
\end{eqn}

Propagation is terminated when the Gross-Pitaevskii energy of the state converges to the required precision (that is, only one component with the lowest energy is left out).
The energy of the two-component condensate~\cite{Pitaevskii2003}
\begin{eqn}
\label{eqn:bec-noise:mean-field:two-comp-energy}
	E[\Psivec] ={} & \int\limits_A \left(
		- \frac{\hbar^2 \Psi_1^* \nabla^2 \Psi_1}{2m}
		- \frac{\hbar^2 \Psi_2^* \nabla^2 \Psi_2}{2m}
	\right. \\
	& \left.
		+ (V_1 + \hbar \omega_1) n_1 + (V_2 + \hbar \omega_2) n_2
		+ \frac{g_{11}}{2} n_1^2 + \frac{g_{22}}{2} n_2^2 + g_{12} n_1 n_2
	\right) \upd\xvec
\end{eqn}
thus has to be calculated after each step and compared to the previous value, waiting for the desired precision to be reached.

\begin{figure}
\begin{center}
\includegraphics[width=0.5\textwidth]{figures_generated/mean_field/two_comp_gs.eps}
\caption{Two-component ground state for immiscible regime.}
\label{fig:mean-field:two-comp-gs}
\end{center}
\end{figure}

\figref{mean-field:two-comp-gs} shows the axial projection of two-component ground state for a mixture of 40,000 $\vert 1 \rangle$ and 40.000 $\vert 2 \rangle$ atoms;
scattering lengths were taken to be equal to $a_{11} = 100.40\ a_0$, $a_{22} = 95.68\ a_0$ and $a_{12} = 98.13\ a_0$, where $a_0$ is the Bohr radius.


% =============================================================================
\subsection{Thomas-Fermi approximation}
% =============================================================================

We are looking for the ground state of the system with pseudopotential model hamiltonian~\cite{Pitaevskii2003}:
\[
	\hat{H} =
		- \frac{\hbar^2}{2m} \frac{\upp^2}{\upp \xvec^2}
		+ V(\xvec)
		+ g_{11} \lvert \Psi(\xvec) \rvert^2,
\]
\[
	g_{11} = \frac{4 \pi \hbar^2 a_{11}}{m},
\]
\begin{equation}
\label{eqn:mean-field:trap-potential}
	V(\xvec) = \frac{m}{2} \left(
		\omega_x^2 x^2 + \omega_y^2 y^2 + \omega_z^2 z^2
	\right).
\end{equation}
where $V(\xvec)$ is the potential energy of parabolic trap, $g_{11}$ is the interaction coefficient,
and $a_{11}$ is the scattering length for atoms in non-excited state.

The ground state satisfies the Gross-Pitaevskii equation~\cite{Pitaevskii2003}:
\begin{equation}
\label{eqn:mean-field:gs-shroedinger}
	\hat{H} \Psi = \mu \Psi,
\end{equation}
where $\mu$ is the chemical potential of the state.
To get the first approximation of the state function,
we consider the kinetic term to be small as compared to other terms and omit it.
The conditions for this operation to be valid will be determined later in this section.
Thus we get the simple equation:
\[
	\left( V(\xvec) + g_{11} \lvert \Psi(\xvec) \rvert^2 \right) \Psi(\xvec) = \mu \Psi(\xvec),
\]
which leads us to the state function:
\begin{equation}
\label{eqn:mean-field:tf-gs}
	\lvert \Psi(\xvec) \rvert^2 = \frac{1}{g_{11}} \max \left( \mu - V(\xvec), 0 \right).
\end{equation}
The condition for $V(\xvec)$ defines the shape of the condensate---it is the ellipsoid with the following radii:
\begin{equation}
\label{eqn:mean-field:tf-radii}
	r_x = \sqrt{\frac{2\mu}{m \omega_x^2}},\,
	r_y = \sqrt{\frac{2\mu}{m \omega_y^2}},\,
	r_z = \sqrt{\frac{2\mu}{m \omega_z^2}}.
\end{equation}

Normalisation condition for the ground state function gives us the connection
between the number of atoms in the condensate and the chemical potential:
\[
	\mu =
		\left( \frac{15 N}{8 \pi} \right)^\frac{2}{5}
		\left( \frac{m \bar{\omega}^2}{2} \right)^\frac{3}{5}
		{g_{11}}^\frac{2}{5},
\]
where $\bar{\omega} = \sqrt[3]{\omega_x \omega_y \omega_z}$.

Now we can roughly estimate the conditions necessary to drop the kinetic term from equation.
Substituting approximate solution~\eqnref{mean-field:tf-gs} to~\eqnref{mean-field:gs-shroedinger}
and comparing kinetic and potential term, we can get the following inequation:
\begin{equation}
\label{eqn:mean-field:tf-inequation}
	\frac{\hbar^2}{2m} \left(
		\frac{m \left( \omega_x^2 + \omega_y^2 + \omega_z^2 \right)}{2}
		+ \frac{m^2 \left( \omega_x^4 x^2 + \omega_y^4 y^2 + \omega_z^4 z^2 \right)}
			{4 \left( \mu - V(\xvec) \right)}
	\right) \ll
	\mu \left(\mu - V(\xvec)\right).
\end{equation}
Near the centre of the condensate this inequation simplifies to
\begin{equation}
\label{eqn:mean-field:tf-condition}
	\mu \gg \frac{\hbar}{2} \sqrt{\omega_x^2 + \omega_y^2 + \omega_z^2}.
\end{equation}

On the other hand, near the edges of the cloud the left-hand side of the inequation~\eqnref{mean-field:tf-inequation} diverges,
while the right-hand side equals zero there.
This means that near the edges Thomas-Fermi approximation fails regardless of the conditions.
Fortunately, the density of the particles there is low, so we can estimate the width $h$ of the "belt"
where our first approximation of the state function is significantly incorrect.
If it happens to be small as compared to the size of the condensate, the approximation can be considered valid.

The first term at the left-hand side of the inequation~\eqnref{mean-field:tf-inequation}
is constant and can be dropped in the limit of $V(\xvec) \rightarrow \mu$.
Then, for the sake of simplicity, we consider two of three coordinates to be zero and the third one to equal to $r - h$,
where $r$ is the corresponding radius of the condensate.
After replacing ``$\ll$'' by ``$\approx$'' and assuming $h$ to be small as compared to $r$,
we obtain the conditions for each coordinate:
\[
	h_x \approx \sqrt{\frac{\hbar^2}{2 \mu m}},\,\ldots
\]
They have to be much smaller than corresponding radii, which gives us:
\[
	\mu \gg \frac{1}{2} \hbar \omega_x,\ldots
\]
These conditions are less strict than the condition for the center of the condensate.
Therefore, we have only one condition justifying the application of Thomas-Fermi approximation is~\eqnref{mean-field:tf-condition}.

\begin{figure}
\begin{center}
\subfloat[100,000 atoms]{\includegraphics[width=0.5\textwidth]{%
	figures_generated/mean_field/ground_states_100k.eps}}
\subfloat[1,000 atoms]{\includegraphics[width=0.5\textwidth]{%
	figures_generated/mean_field/ground_states_1k.eps}}
\end{center}
\caption{Numerically calculated and Thomas-Fermi approximated ground states}
\label{fig:mean-field:tf-vs-accurate}
\end{figure}

Let us use some real-life experimental parameters and check how well Thomas-Fermi approximation works.
For three-dimensional trap with frequencies $f_x = f_y = 97.6 \textrm{ Hz}$ and $f_x = 11.96 \textrm{ Hz}$
and $10^5$ rubidium atoms (which have scattering length $a_{11} = 100.4 a_0$, where $a_0$ is the Bohr radius),
we have $\mu \approx 7.67 \hbar \omega_x$.
This means that Thomas-Fermi approximation produces solution which is close to the real one.
But for lower amount of atoms, say $10^3$, we get $\mu \approx 1.28 \hbar \omega_x$,
which is a sign that the we are reaching the limit of the approximation's applicability.
\figref{mean-field:tf-vs-accurate} shows the density along the z axis for both cases:
for $10^5$ atoms Thomas-Fermi approximation is very close to accurately calculated ground state (see the following section for details),
and for $10^3$ atoms it differs significantly, as expected.


