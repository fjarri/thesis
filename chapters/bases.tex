% =============================================================================
\chapter{Basis sets}
\label{cha:appendix:bases}
% =============================================================================

While it is possible to apply the central theorems from this thesis to many different basis sets satisfying the orthonormality and completeness conditions~\eqnref{func-calculus:basis}, other factors restrict the choice in practical applications.
Ideally, one would want the following to be true:
\begin{itemize}
    \item the basis modes are natural to the physical problem in question (e.g., plain waves for a freely expanding \abbrev{bec});
    \item decomposition of a function defined on a discrete spatial grid in the basis is computationally effective; and
    \item the generalised periodicity condition from \lmmref{func-calculus:move-laplacian} applies.
\end{itemize}

For the applications discussed in this thesis, the first condition is the hardest to satisfy since the equations we use are nonlinear, which makes ground and excited states of the system inexpressible algebraically (with some exceptions, e.g. when the nonlinearity is negligible).
The advantage of this condition being satisfied is that fewer modes will be required to describe the dynamics of a system, thus making it easier to satisfy the Wigner truncation condition (see \secref{wigner-bec:truncation} for details).

Taking this into account, we have settled on two basis sets to use in the calculations.
The plane wave basis was used as the primary one, and the harmonic oscillator basis was used as the backup.
In practice, the latter was not very useful for the simulations considered in this thesis since it required roughly the same number of modes as the plane wave basis, and was more difficult to work with from the computational point of view.
Nevertheless, we are including its description in this Appendix as it may still be useful for different (e.g. one-dimensional) systems.


% =============================================================================
\section{Plane wave basis}
% =============================================================================

The plane wave basis consists of eigenfunctions of the kinetic term of a Hamiltonian:
\begin{eqn}
    \left( -\frac{\hbar^2}{2m} \nabla^2 \right) \phi_{\nvec}
    = E_{\nvec} \phi_{\nvec}.
\end{eqn}
The eigenfunctions are defined in a $D$-dimensional box with the shape $(L_1, \ldots, L_D)$ with $\prod_{d=1}^D L_d \equiv V$ (which corresponds to the integration area $A$ introduced in \appref{func-calculus}):
\begin{eqn}
\label{eqn:bases:plane-wave-modes}
    \phi_{\nvec}(\xvec) = e^{i \kvec_{\nvec} \xvec} / \sqrt{V},
\end{eqn}
and have the corresponding eigenvalues (energies)
\begin{eqn}
    E_{\nvec}
    = \frac{\hbar^2 \lvert \kvec_{\nvec} \rvert^2}{2 m}.
\end{eqn}
Because of the periodic boundary conditions at the edges of the box, possible values of the components of the spatial frequency vector $\kvec$ are
\begin{eqn}
    (\kvec_{\nvec})_d = \frac{2 \pi n_d}{L_d}.
\end{eqn}

This basis set is the most computationally effective.
Functions defined on the discrete grid $x_d = 0, h, \ldots, L_d - h$ (the step $d = L_d / M_d$, where $M_d$ is the number of modes in the dimension $d$) can be decomposed into this basis using the Fast Fourier transform (\abbrev{fft}), which is available for a wide range of platforms and programming languages, and has the asymptotical complexity $\mathcal{O}(M \log_2 M)$ (where the total number of modes $M = \prod_{d=1}^D M_d$).

While this basis is far from being natural for a harmonically confined \abbrev{bec} with nonlinear interactions, its effectiveness overweighs all the disadvantages; plane wave modes can be viewed as pixels for the mode space.


% =============================================================================
\section{Harmonic oscillator basis}
% =============================================================================

It often happens that, for a pseudo-\abbrev{1d} \abbrev{bec}, the confinement in transverse dimensions is strong enough to make the nonlinear interaction negligible.
In these cases, it can be advantageous to use the harmonic oscillator basis for these dimensions despite its computational drawbacks.

The harmonic basis consists of eigenfunctions of the kinetic and potential terms of a Hamiltonian:
\begin{eqn}
    \left(
        -\frac{\hbar^2}{2m} \nabla^2
        + \frac{m \sum_{d=1}^D \omega_d^2 x_d^2}{2}
    \right) \phi_{\nvec}
    = E_{\nvec} \phi_{\nvec}.
\end{eqn}
The eigenfunctions are
\begin{eqn}
\label{eqn:bases:harmonic-modes}
    \phi_{\nvec}
    = \prod_{d=1}^D \phi_{n_d}^{(d)} (x_d)
    = \prod_{d=1}^D
        \frac{1}{\sqrt{2^{n_d} n_d! l_d} \sqrt[4]{\pi}}
        H_{n_d} \left( \frac{x_d}{l_d} \right)
        \exp \left( -\frac{x_d^2}{2 l_d^2} \right),
\end{eqn}
where $H_{n_d}$ is the ``physicists'\,'' Hermite polynomial of order $n_d$, and $l_d = \sqrt{\hbar / (m \omega_d)}$ is the characteristic length.
The corresponding eigenvalues are
\begin{eqn}
    E_{\nvec} = \hbar \sum_{d=1}^D \omega_d (n_d + \frac{1}{2}).
\end{eqn}

Decomposition into this basis is less computationally effective than \abbrev{fft} in terms of speed, memory, and even precision (due to extremely large range of weight coefficients needed for the decomposition).
There are even some restrictions on the function being transformed.
The next section describes the algorithm and these restrictions in detail.


% =============================================================================
\section{Discrete harmonic transformation}
% =============================================================================

The numerical algorithm for the decomposition of a function defined on a discrete grid in the harmonic basis~\cite{Dion2003} is much less known than the \abbrev{fft} and has some unusual properties, so it is worth describing in brief.

Given some function $f(\xvec)$, one can expand it into the harmonic oscillator basis as
\begin{eqn}
    \alpha_{\nvec}
    = (\mathcal{C}^{-1}[f])_{\nvec}
    \equiv \int f(x) \phi_{\nvec}^*(\xvec) \upd \xvec,
\end{eqn}
where we have used the terminology from \appref{func-calculus}.
The corresponding backward transformation is
\begin{eqn}
    f(\xvec)
    = \mathcal{C}[f] (\balpha)
    \equiv \sum_{\nvec \in \fullbasis} \alpha_{\nvec} \phi_{\nvec}(\xvec).
\end{eqn}
In general, when we do not know anything about $f(\xvec)$, and only have its value sampled at some set of points, the value of the integral can be calculated only approximately.
However, we can obtain exact results for functions of a certain kind if we are allowed to choose the sampling points.

The method is based on the Gauss-Hermite quadrature~\cite{Abramowitz1972}, which states that the value of a Gaussian weighted integral can be approximated as a weighted sum:
\begin{eqn}
\label{eqn:bases:gh-quadrature}
    \int\limits_{-\infty}^{\infty} g(x) e^{-x^2} \upd x
    = \sum_{i=1}^N w_i g(r_i) + E,
\end{eqn}
where $N$ is the number of sample points.
The weights $w_i$ are calculated as
\begin{eqn}
    w_i = \frac{2^{N-1} N! \sqrt{\pi}}{N^2 (H_{N-1}(r_i))^2},
\end{eqn}
and the sample points $r_i$ are the roots of the Hermite polynomial $H_N$.
The error term is
\begin{eqn}
    E = \frac{N! \sqrt{\pi}}{2^N (2N)!} g^{(2N)}(\xi).
\end{eqn}
Therefore if $g(x)$ is a polynomial of order $Q$, one can eliminate the error term by choosing $N$ so that $2N \ge Q + 1$, thus making the quadrature exact.

In practical applications, we are dealing with restricted bases.
Without loss of generality, we can consider a restricted basis to be consisting of the first several low-energy modes.
If the modes are actually sparse, it will only reduce the effectiveness of the method because we can always assume that we are dealing with sequential modes up to the maximum one and then drop all the superfluous components from the result.


% =============================================================================
\subsection{One-dimensional case}
% =============================================================================

Let us consider a one-dimensional case first, with a function $\Psi(x) \in \mathbb{F}_{\restbasis}$, where $|\restbasis| = M$.
We want to find the population of the first $M^\prime$ modes for the decomposition of $f(x) = \Psi^s(x)$, where $s$ is a natural number (note that, despite the original function $\Psi$ having non-zero population only in a finite number of modes, $\Psi^s$ may, in general, have an infinite number of modes in its decomposition).
This means that we need to calculate
\begin{eqn}
    \alpha_m = \int \Psi^s(x) \phi_m^*(x) \upd x.
\end{eqn}
By definition of the mode functions~\eqnref{bases:harmonic-modes},
\begin{eqn}
\label{eqn:bases:polynomial-integrand}
    \Psi^s(x) \phi_m^*(x) = P(x / l_x) \exp \left( -\frac{(s+1) x^2}{2 l_x^2} \right),
\end{eqn}
where $P(x)$ is a polynomial of order less than or equal to $(M-1)s + m$.
Since we want to have the same set of sample points for any $m \in [0, M^\prime-1]$, we will consider the worst case $m = M^\prime-1$, which makes the order of $P(x)$ limited by $(M-1)s + M^\prime - 1$.
Changing variables in the integral to make it comply to the form~\eqnref{bases:gh-quadrature} and applying the quadrature, we get:
\begin{eqn}
    \alpha_m
    & = \int P(x / l_x) \exp \left( -\frac{(s+1) x^2}{2 l_x^2} \right) dx \\
    & = l_x \sqrt{\frac{2}{s+1}} \int P \left( y \sqrt{\frac{2}{s+1}} \right) e^{-y^2} dy \\
    & = l_x \sqrt{\frac{2}{s+1}} \sum_{i=1}^N w_i P \left( r_i \sqrt{\frac{2}{s+1}} \right),
\end{eqn}
where the number of sampling points necessary to make the quadrature exact is determined by the order of $P(x)$:
\begin{eqn}
    N \ge \frac{(M - 1)s + M^\prime}{2}.
\end{eqn}
Replacing $P$ with $\Psi$ and $\phi$ using~\eqnref{bases:polynomial-integrand}:
\begin{eqn}
    \alpha_m
    & = l_x \sqrt{\frac{2}{s+1}}
        \sum_{i=1}^N w_i
        \Psi^s \left( l_x r_i \sqrt{\frac{2}{s+1}} \right)
        \phi_m^* \left( l_x r_i \sqrt{\frac{2}{s+1}} \right)
        \exp(r_i^2) \\
    & = \sum_{i=1}^N \tilde{w}_i \phi_m(\tilde{x}_i) f(\tilde{x}_i),
\end{eqn}
where the modified sampling points are
\begin{eqn}
    \tilde{x}_i = l_x r_i \sqrt{\frac{2}{s+1}},
\end{eqn}
and the modified weights are
\begin{eqn}
\label{eqn:bases:gh-weights}
    \tilde{w}_i = w_i l_x \sqrt{\frac{2}{s+1}} \exp(r_i^2).
\end{eqn}

Since we usually need the population of all modes at once, it is more convenient to use the matrix form of the discrete harmonic transformation (\abbrev{dht}):
\begin{eqn}
    \balpha
    = G(\mathbf{f})
    \equiv \Phi^T\,\mathrm{diag}(\tilde{\mathbf{w}}) \mathbf{f}
    \equiv \Phi^T (\tilde{\mathbf{w}} \circ \mathbf{f}),
\end{eqn}
where $\Phi_{im} = \phi_m(\tilde{x}_i)$ is an $N \times M^\prime$ matrix, $\tilde{\mathbf{w}}$ is an $N$-vector of elements $\tilde{w}_i$, $\mathbf{f}$ is an $N$-vector of elements $f(\tilde{x}_i)$, and the symbol $\circ$ stands for the Hadamard (element wise) product.
The corresponding backward transformation is then expressed as
\begin{eqn}
    \mathbf{f}
    = G^{-1}(\balpha)
    \equiv \Phi \balpha.
\end{eqn}

There are a few catches in the practical implementation of this algorithm.
First, there can be significant round-off errors during the expansion for the large $N$ due to the exponential term in the expression for weights~\eqnref{bases:gh-weights}.
Second, note that $G^{-1}(G(\mathbf{f})) \ne \mathbf{f}$ for $s > 1$, since during the expansion we are effectively discarding the higher-order modes of $\Psi^s$ and are thus losing some information.
For $s = 1$ and $M^\prime \ge M$ though the transformation is reversible.

Lastly, since the known order $s$ is hard-coded into the algorithm, including the values of the sampling points, one has to transform different orders of the known function from $\mathbb{F}_{\restbasis}$ separately.
This is a usual case when the \abbrev{dht} is used to solve a nonlinear Schr\"odinger equation in momentum space.
For a concrete example, consider an equation
\begin{eqn}
    i \hbar \frac{\upd \Psi}{\upd t}
    = -\frac{\hbar^2}{2m} \nabla^2 \Psi
        + \frac{m \omega^2 x^2}{2} \Psi
        + g \Psi |\Psi|^2
        - i \gamma \Psi |\Psi|^4.
\end{eqn}
If this equation is propagated in momentum space, the last two terms have to be transformed using different transformations because the first one has the order $s=3$, and the second one has the order $s=5$:
\begin{eqn}
    i \hbar \frac{\upd \balpha}{\upd t}
    = \mathbf{E} \cdot \balpha
        + g G_{s=3}(G_{s=3}^{-1}(\balpha) |G_{s=3}^{-1}(\balpha)|^2)
        - i \gamma G_{s=5}(G_{s=5}^{-1}(\balpha) |G_{s=5}^{-1}(\balpha)|^4).
\end{eqn}


% =============================================================================
\subsection{Multi-dimensional case}
% =============================================================================

The \abbrev{dht} can be easily generalized to operate in several dimensions.
Basically, we need to apply the \abbrev{1d} transformation for each dimension successively.
If $F_{ij\ldots} = f(\tilde{x}_i^{(1)}, \tilde{x}_j^{(2)}, \ldots)$ is a $D$-dimensional matrix of shape $N_1 \times N_2 \times \ldots \times N_D$ consisting of samples of $f$ taken on the discrete grid
\begin{eqn}
    \tilde{x}_i^{(d)} = l_x^{(d)} r_i^{(d)} \sqrt{\frac{2}{s+1}},
\end{eqn}
then for every dimension $d$ we want to perform the transformation, we need to:
\begin{itemize}
    \item perform the multidimensional transposition $F^\prime = T_{1 \leftrightarrow d} [F]$, which changes the shape of $F$ to $N_d \times N_2 \times \ldots \times N_1 \times \ldots \times N_D$ (i.e., makes the $d$-th dimension major);
    \item calculate the dot product $C^\prime = (\Phi^{(d)})^T\,\mathrm{diag}(\tilde{\mathbf{w}}^{(d)}) F^\prime$, where $\Phi_{im}^{(d)} = \phi_m^{(d)}(\tilde{x}_i^{(d)})$ is an $N_d \times M_d^\prime$ matrix, $\tilde{\mathbf{w}}^{(d)}$ is an $N_d$-vector of weights
    \begin{eqn}
        \tilde{w}_i^{(d)} = w_i^{(d)} l_x^{(d)} \sqrt{\frac{2}{s+1}} \exp((r_i^{(d)})^2),
    \end{eqn}
    and $F^\prime$ is treated as a 2-dimensional matrix of shape $N_d \times N_2 \ldots N_1 \ldots N_D$;
    \item perform the backward transposition $C = T_{1 \leftrightarrow d} [C^\prime]$.
\end{itemize}

In a single expression, it is a composition of two transpositions and one dot product:
\begin{eqn}
    G_d
    \equiv
        T_{1 \leftrightarrow d}
        ((\Phi^{(d)})^T\,\mathrm{diag}(\tilde{\mathbf{w}}^{(d)}) \cdot)
        T_{1 \leftrightarrow d},
\end{eqn}
with backward transformation
\begin{eqn}
    G_d^{-1}
    \equiv
        T_{1 \leftrightarrow d}
        (\Phi^{(d)} \cdot)
        T_{1 \leftrightarrow d},
\end{eqn}
These \abbrev{1d} transformations can be applied in an arbitrary order for all the required dimensions.
